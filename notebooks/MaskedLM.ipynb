{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MaskedLM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "kXCGydVL7IZk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Masked Language Model Test\n",
        "\n",
        "We will test here whether a BERT model can predict masked Mongolian words. We will download and test the cased BERT-Base model. For other available Mongolian BERT models see [tugstugi/mongolian-bert](https://github.com/tugstugi/mongolian-bert).\n",
        "\n",
        "\n",
        "Download the model, install needed dependencies and initialize the model:"
      ]
    },
    {
      "metadata": {
        "id": "8nyk-GYK4-Je",
        "colab_type": "code",
        "outputId": "5a78906e-555f-4b54-dbfc-6292ca137df4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "import sys\n",
        "\n",
        "def download_from_google_drive(file_id, file_name):\n",
        "  # download a file from the Google Drive link\n",
        "  !rm -f ./cookie\n",
        "  !curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id={file_id}\" > /dev/null\n",
        "  confirm_text = !awk '/download/ {print $NF}' ./cookie\n",
        "  confirm_text = confirm_text[0]\n",
        "  !curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm={confirm_text}&id={file_id}\" -o {file_name}\n",
        "  \n",
        "# download a pre-trained model\n",
        "model_path = 'cased_bert_base_pytorch'\n",
        "if not exists(model_path):\n",
        "  download_from_google_drive('11Adpo6DorPgpE8z1lL6rvZAMHLEfnJwv', '%s.zip' % model_path)\n",
        "  !unzip {model_path}.zip\n",
        "  sys.path.append(model_path)\n",
        "  \n",
        "# we need only sentencepience and pytorch-pretrained-BERT, everything else is included in the downloaded model\n",
        "!pip install -q pytorch-pretrained-BERT sentencepiece\n",
        "\n",
        "# import needed modules\n",
        "import torch\n",
        "from tokenization_sentencepiece import FullTokenizer\n",
        "import pytorch_pretrained_bert\n",
        "from pytorch_pretrained_bert import BertModel, BertForMaskedLM, BertForNextSentencePrediction\n",
        "\n",
        "# Load pre-trained model tokenizer\n",
        "tokenizer = FullTokenizer(model_file=join(model_path, 'mn_cased.model'), vocab_file=join(model_path, 'mn_cased.vocab'), do_lower_case=False)\n",
        "# Load pre-trained model (weights)\n",
        "model = BertForMaskedLM.from_pretrained(model_path)\n",
        "model = model.eval()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   388    0   388    0     0   4674      0 --:--:-- --:--:-- --:--:--  4674\n",
            "100  394M    0  394M    0     0  49.8M      0 --:--:--  0:00:07 --:--:-- 65.6M\n",
            "Archive:  cased_bert_base_pytorch.zip\n",
            "   creating: cased_bert_base_pytorch/\n",
            "  inflating: cased_bert_base_pytorch/eval_results.txt  \n",
            "  inflating: cased_bert_base_pytorch/mn_cased.model  \n",
            "  inflating: cased_bert_base_pytorch/mn_cased.vocab  \n",
            "  inflating: cased_bert_base_pytorch/tokenization_sentencepiece.py  \n",
            "  inflating: cased_bert_base_pytorch/bert_config.json  \n",
            "  inflating: cased_bert_base_pytorch/pytorch_model.bin  \n",
            "\u001b[K    100% |████████████████████████████████| 122kB 4.6MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 1.0MB 17.6MB/s \n",
            "\u001b[?25hBetter speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
            "Loaded a trained SentencePiece model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6GSzkuk3f0HF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will mask the following Mongolian sentence and try to predict the masked word:"
      ]
    },
    {
      "metadata": {
        "id": "36NcE_xy5rJf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TEXT = 'Орчин үеийн стандартын усан спортын бассейныг ирэх онд ашиглалтад оруулна.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZHtuuM9WhZTT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tokenize the above text:"
      ]
    },
    {
      "metadata": {
        "id": "C9I6_XmIhbEW",
        "colab_type": "code",
        "outputId": "43d31bd4-c0d1-416a-b70f-eb4d34db2392",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "tokenized_text = tokenizer.tokenize(TEXT)\n",
        "\" \".join(tokenized_text)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'▁Орчин ▁үеийн ▁стандартын ▁усан ▁спортын ▁бассейн ыг ▁ирэх ▁онд ▁ашиглалтад ▁оруулна .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "qyYPYFWZgxIh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Mask the token `▁ашиглалтад`:"
      ]
    },
    {
      "metadata": {
        "id": "aAPS-BacLMyI",
        "colab_type": "code",
        "outputId": "6db96a7b-f07c-408f-8f0c-6e94872338f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "masked_index = tokenized_text.index('▁ашиглалтад')\n",
        "tokenized_text[masked_index] = '[MASK]'\n",
        "\" \".join(tokenized_text)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'▁Орчин ▁үеийн ▁стандартын ▁усан ▁спортын ▁бассейн ыг ▁ирэх ▁онд [MASK] ▁оруулна .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "YU-Iunrbh0AA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now predict:"
      ]
    },
    {
      "metadata": {
        "id": "mxGc4eNy4_65",
        "colab_type": "code",
        "outputId": "fb40980a-da50-468e-c404-c9d5799af535",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# index and segment ids\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "segments_ids = [0]*len(indexed_tokens);\n",
        "len(segments_ids) == len(tokenized_text)\n",
        "\n",
        "# Predict all tokens\n",
        "with torch.no_grad():\n",
        "    predictions = model(torch.tensor([indexed_tokens]), torch.tensor([segments_ids]))\n",
        "\n",
        "# confirm we were able to predict the masked word\n",
        "predicted_index = torch.argmax(predictions[0, masked_index]).item()\n",
        "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
        "predicted_token"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'▁ашиглалтад'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    }
  ]
}